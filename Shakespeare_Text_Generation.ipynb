{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "396cbfae-74e3-4fc4-9437-f6bb990f28f7",
   "metadata": {},
   "source": [
    "# <center> Shakespeare Text Generation with LSTM </center>\n",
    "This notebook demonstrates how to use an LSTM (Long Short-Term Memory) neural network to generate text inspired by Shakespeare's works. The process includes downloading the data, preprocessing it, and using a pre-trained model to generate text based on a seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "922fe3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Modules\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5c1c692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading and Preparing Data\n",
    "filepath = tf.keras.utils.get_file(\n",
    "    \"shakespeare.txt\", \n",
    "    \"https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\"\n",
    ")\n",
    "\n",
    "text = open(filepath, \"rb\").read().decode(encoding=\"utf-8\").lower()  # Lower case for consistency\n",
    "chars = sorted(set(text))  # Unique characters in the text\n",
    "\n",
    "# Character-to-index and index-to-character mappings\n",
    "char_to_index = {char: i for i, char in enumerate(chars)}\n",
    "index_to_char = {i: char for i, char in enumerate(chars)}\n",
    "\n",
    "# Create input-output sequences\n",
    "max_len = 40  # Sequence length\n",
    "step = 3      # Step size for creating sequences\n",
    "\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - max_len, step):\n",
    "    sentences.append(text[i: i + max_len])\n",
    "    next_chars.append(text[i + max_len])\n",
    "\n",
    "# One-hot encoding of input and output sequences\n",
    "x = np.zeros((len(sentences), max_len, len(chars)), dtype=np.bool_)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool_)\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_to_index[char]] = 1\n",
    "    y[i, char_to_index[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf00f624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "\u001b[1m1453/1453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 86ms/step - loss: 2.2219\n",
      "Epoch 2/4\n",
      "\u001b[1m1453/1453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 82ms/step - loss: 1.6063\n",
      "Epoch 3/4\n",
      "\u001b[1m1453/1453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 79ms/step - loss: 1.5015\n",
      "Epoch 4/4\n",
      "\u001b[1m1453/1453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 80ms/step - loss: 1.4536\n"
     ]
    }
   ],
   "source": [
    "# Uncomment this section to train the model and save it\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(max_len, len(chars))))\n",
    "model.add(Dense(len(chars), activation=\"softmax\"))\n",
    "\n",
    "optimizer = RMSprop(learning_rate=0.01)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer)\n",
    "\n",
    "# Train the model\n",
    "model.fit(x, y, batch_size=256, epochs=4)\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"shakesspeare.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00f214dd-008d-49c5-a1c0-94b24e37b221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Sucsesfuly\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(r\"C:\\\\Users\\\\Noticed Aaryan\\\\Desktop\\\\Shakesspeare AI\\\\shakesspeare.keras\")\n",
    "print(\"Loaded Sucsesfuly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "235642f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature sampling function for diversity in predictions\n",
    "def sample_with_temperature(predictions, temperature=1.0):\n",
    "    predictions = np.log(predictions + 1e-10) / temperature\n",
    "    probabilities = np.exp(predictions) / np.sum(np.exp(predictions))\n",
    "    return np.random.choice(len(probabilities), p=probabilities)\n",
    "\n",
    "# Generate text function\n",
    "def generate_text(seed_text, output_length, temperature=1.0):\n",
    "    generated_text = seed_text\n",
    "    if len(seed_text) < max_len:\n",
    "        seed_text = seed_text.rjust(max_len)\n",
    "    elif len(seed_text) > max_len:\n",
    "        seed_text = seed_text[-max_len:]\n",
    "    \n",
    "    for _ in range(output_length):\n",
    "        # Prepare input sequence\n",
    "        input_seq = np.zeros((1, max_len, len(chars)))\n",
    "        for t, char in enumerate(seed_text):\n",
    "            input_seq[0, t, char_to_index.get(char, 0)] = 1.0\n",
    "        \n",
    "        # Predict the next character probabilities\n",
    "        predictions = model.predict(input_seq, verbose=0)[0]\n",
    "        next_index = sample_with_temperature(predictions, temperature)\n",
    "        next_char = index_to_char[next_index]\n",
    "        \n",
    "        # Append to generated text and update seed\n",
    "        generated_text += next_char\n",
    "        seed_text = seed_text[1:] + next_char\n",
    "    \n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c47d75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________0.3_____________________\n",
      "Am i chines?\n",
      "\n",
      "coriolanus:\n",
      "who the tright is the soul of the charge.\n",
      "\n",
      "buckingham:\n",
      "the senate of our stallers of the company.\n",
      "\n",
      "second citizen:\n",
      "i have so minither the life of my lord.\n",
      "\n",
      "benvolio:\n",
      "i have death your cou\n",
      "_____________________0.5_____________________\n",
      "Am i chines?\n",
      "\n",
      "lady anne:\n",
      "who is it with englenter hearth with an his charce,\n",
      "and he would the country's son of one earth,\n",
      "the death, herefore that for the earth,\n",
      "than the rest of us shall have in the friends,\n",
      "but \n",
      "_____________________0.7_____________________\n",
      "Am i chines?\n",
      "\n",
      "petruchio:\n",
      "good king is most mean are my other.\n",
      "o, the thing with a death, be shall hear and be with thanks,\n",
      "and my quietly even more to be comn to be see\n",
      "the shrunger with my fathers with my king,\n",
      "t\n",
      "_____________________0.9_____________________\n",
      "Am i chines?\n",
      "\n",
      "cominius:\n",
      "rely for thy officer\n",
      "mercy and see your tribunes, and a letter\n",
      "of wrong?\n",
      "and he for a house, ment-stofd's. you see,\n",
      "what done we commandent thee to requile\n",
      "a lating kined, butwith he brings\n",
      "_____________________1_____________________\n",
      "Am i chines?\n",
      "\n",
      "cate liactrem:\n",
      "thou say is tivel's gigbreghius wooding,\n",
      "hathar shall give the tlary shrow.\n",
      "\n",
      "romeo:\n",
      "as no to in\n",
      "modh, good mother his,\n",
      "where you must and so? i do be to then.\n",
      "\n",
      "polixenes:\n",
      "we have desci\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "seed = \"Am i chines?\\n\"\n",
    "output_length = 200  # Number of characters to generate\n",
    "temp = [0.3, 0.5, 0.7 , 0.9 , 1 ]\n",
    "for t in temp:\n",
    "    print(f\"_____________________{t}_____________________\")\n",
    "    print(generate_text(seed, output_length, temperature= t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c83e56d-c925-4f64-838a-172af11675f8",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
